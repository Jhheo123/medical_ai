훈련 로그 시작

Epoch 1 시작
Batch [1/858], Loss: 0.7210
Batch [2/858], Loss: 0.5428
Batch [3/858], Loss: 0.3350
Batch [4/858], Loss: 0.2341
Batch [5/858], Loss: 0.2160
Batch [6/858], Loss: 0.2185
Batch [7/858], Loss: 0.1843
Batch [8/858], Loss: 0.1790
Batch [9/858], Loss: 0.1882
Batch [10/858], Loss: 0.1857
Batch [11/858], Loss: 0.1766
Batch [12/858], Loss: 0.1709
Batch [13/858], Loss: 0.1947
Batch [14/858], Loss: 0.1643
Batch [15/858], Loss: 0.1710
Batch [16/858], Loss: 0.1627
Batch [17/858], Loss: 0.1614
Batch [18/858], Loss: 0.1704
Batch [19/858], Loss: 0.2041
Batch [20/858], Loss: 0.1602
Batch [21/858], Loss: 0.1844
Batch [22/858], Loss: 0.1730
Batch [23/858], Loss: 0.1681
Batch [24/858], Loss: 0.1447
Batch [25/858], Loss: 0.1662
Batch [26/858], Loss: 0.1812
Batch [27/858], Loss: 0.1553
Batch [28/858], Loss: 0.1626
Batch [29/858], Loss: 0.1743
Batch [30/858], Loss: 0.1618
Batch [31/858], Loss: 0.1722
Batch [32/858], Loss: 0.1725
Batch [33/858], Loss: 0.1461
Batch [34/858], Loss: 0.1515
Batch [35/858], Loss: 0.1883
Batch [36/858], Loss: 0.1362
Batch [37/858], Loss: 0.1459
Batch [38/858], Loss: 0.1646
Batch [39/858], Loss: 0.1660
Batch [40/858], Loss: 0.1732
Batch [41/858], Loss: 0.1559
Batch [42/858], Loss: 0.1530
Batch [43/858], Loss: 0.1537
Batch [44/858], Loss: 0.1808
Batch [45/858], Loss: 0.1731
Batch [46/858], Loss: 0.1611
Batch [47/858], Loss: 0.1567
Batch [48/858], Loss: 0.1790
Batch [49/858], Loss: 0.1576
Batch [50/858], Loss: 0.1588
Batch [51/858], Loss: 0.1558
Batch [52/858], Loss: 0.1510
Batch [53/858], Loss: 0.1643
Batch [54/858], Loss: 0.1451
Batch [55/858], Loss: 0.1615
Batch [56/858], Loss: 0.1568
Batch [57/858], Loss: 0.1544
Batch [58/858], Loss: 0.1580
Batch [59/858], Loss: 0.1649
Batch [60/858], Loss: 0.1628
Batch [61/858], Loss: 0.1625
Batch [62/858], Loss: 0.1525
Batch [63/858], Loss: 0.1489
Batch [64/858], Loss: 0.1560
Batch [65/858], Loss: 0.1573
Batch [66/858], Loss: 0.1561
Batch [67/858], Loss: 0.1539
Batch [68/858], Loss: 0.1408
Batch [69/858], Loss: 0.1392
Batch [70/858], Loss: 0.1688
Batch [71/858], Loss: 0.1586
Batch [72/858], Loss: 0.1595
Batch [73/858], Loss: 0.1444
Batch [74/858], Loss: 0.1452
Batch [75/858], Loss: 0.1829
Batch [76/858], Loss: 0.1443
Batch [77/858], Loss: 0.1456
Batch [78/858], Loss: 0.1671
Batch [79/858], Loss: 0.1608
Batch [80/858], Loss: 0.1575
Batch [81/858], Loss: 0.1546
Batch [82/858], Loss: 0.1602
Batch [83/858], Loss: 0.1559
Batch [84/858], Loss: 0.1510
Batch [85/858], Loss: 0.1610
Batch [86/858], Loss: 0.1565
Batch [87/858], Loss: 0.1544
Batch [88/858], Loss: 0.1462
Batch [89/858], Loss: 0.1582
Batch [90/858], Loss: 0.1443
Batch [91/858], Loss: 0.1510
Batch [92/858], Loss: 0.1385
Batch [93/858], Loss: 0.1713
Batch [94/858], Loss: 0.1556
Batch [95/858], Loss: 0.1505
Batch [96/858], Loss: 0.1530
Batch [97/858], Loss: 0.1596
Batch [98/858], Loss: 0.1642
Batch [99/858], Loss: 0.1294
Batch [100/858], Loss: 0.1328
Batch [101/858], Loss: 0.1580
Batch [102/858], Loss: 0.1474
Batch [103/858], Loss: 0.1270
Batch [104/858], Loss: 0.1642
Batch [105/858], Loss: 0.1356
Batch [106/858], Loss: 0.1812
Batch [107/858], Loss: 0.1555
Batch [108/858], Loss: 0.1232
Batch [109/858], Loss: 0.1512
Batch [110/858], Loss: 0.1587
Batch [111/858], Loss: 0.1538
Batch [112/858], Loss: 0.1297
Batch [113/858], Loss: 0.1568
Batch [114/858], Loss: 0.1370
Batch [115/858], Loss: 0.1346
Batch [116/858], Loss: 0.1228
Batch [117/858], Loss: 0.1587
Batch [118/858], Loss: 0.1741
Batch [119/858], Loss: 0.1620
Batch [120/858], Loss: 0.1556
Batch [121/858], Loss: 0.1409
Batch [122/858], Loss: 0.1370
Batch [123/858], Loss: 0.1560
Batch [124/858], Loss: 0.1472
Batch [125/858], Loss: 0.1695
Batch [126/858], Loss: 0.1487
Batch [127/858], Loss: 0.1287
Batch [128/858], Loss: 0.1346
Batch [129/858], Loss: 0.1440
Batch [130/858], Loss: 0.1258
Batch [131/858], Loss: 0.1370
Batch [132/858], Loss: 0.1559
Batch [133/858], Loss: 0.1426
Batch [134/858], Loss: 0.1448
Batch [135/858], Loss: 0.1655
Batch [136/858], Loss: 0.1582
Batch [137/858], Loss: 0.1310
Batch [138/858], Loss: 0.1539
Batch [139/858], Loss: 0.1470
Batch [140/858], Loss: 0.1486
Batch [141/858], Loss: 0.1569
Batch [142/858], Loss: 0.1430
Batch [143/858], Loss: 0.1566
Batch [144/858], Loss: 0.1175
Batch [145/858], Loss: 0.1531
Batch [146/858], Loss: 0.1503
Batch [147/858], Loss: 0.1352
Batch [148/858], Loss: 0.1540
Batch [149/858], Loss: 0.1299
Batch [150/858], Loss: 0.1605
Batch [151/858], Loss: 0.1278
Batch [152/858], Loss: 0.1267
Batch [153/858], Loss: 0.1474
Batch [154/858], Loss: 0.1405
Batch [155/858], Loss: 0.1419
Batch [156/858], Loss: 0.1352
Batch [157/858], Loss: 0.1158
Batch [158/858], Loss: 0.1523
Batch [159/858], Loss: 0.1444
Batch [160/858], Loss: 0.1371
Batch [161/858], Loss: 0.1382
Batch [162/858], Loss: 0.1495
Batch [163/858], Loss: 0.1445
Batch [164/858], Loss: 0.1425
Batch [165/858], Loss: 0.1656
